#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LUMEN - ì˜í•™ ì •ë³´ íë ˆì´ì…˜ ì‚¬ì´íŠ¸ (ì¤‘ê¸° ê°œì„  ë²„ì „)
- ì„¤ì • íŒŒì¼ ë¶„ë¦¬ (config.py)
- ë°ì´í„°ë² ì´ìŠ¤ ë„ì… (SQLite)
- ì—ëŸ¬ ì•Œë¦¼ ì‹œìŠ¤í…œ (ì´ë©”ì¼)
"""

import os
from dotenv import load_dotenv
import feedparser
from datetime import datetime, timezone, timedelta
import time
import requests
import json
import re
import logging
import hashlib
import asyncio
import aiohttp
from typing import Dict, List, Tuple, Optional
from difflib import SequenceMatcher
import sqlite3
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# ì„¤ì • íŒŒì¼ import
import config

# =========================================================
# ë¡œê¹… ì„¤ì •
# =========================================================
logging.basicConfig(
    level=getattr(logging, config.LOGGING_CONFIG['level']),
    format=config.LOGGING_CONFIG['format'],
    handlers=[
        logging.FileHandler(config.LOGGING_CONFIG['file'], encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# =========================================================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# =========================================================
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
EMAIL_USER = os.getenv("EMAIL_USER")
EMAIL_PASS = os.getenv("EMAIL_PASS")
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")

if not GEMINI_API_KEY:
    logger.error("âŒ GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit(1)

logger.info("ğŸ”‘ API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

# =========================================================
# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
# =========================================================
def init_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
    if not config.DATABASE_CONFIG['enabled']:
        return
    
    try:
        conn = sqlite3.connect(config.DATABASE_CONFIG['path'])
        cursor = conn.cursor()
        
        # ë‰´ìŠ¤ í…Œì´ë¸” ìƒì„±
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS news (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                original_title TEXT NOT NULL,
                translated_title TEXT,
                short_summary TEXT,
                long_summary TEXT,
                category TEXT,
                url TEXT UNIQUE,
                source TEXT,
                publish_date DATE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ì‹¤í–‰ ë¡œê·¸ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS execution_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                start_time TIMESTAMP,
                end_time TIMESTAMP,
                duration_seconds REAL,
                news_count INTEGER,
                cache_hits INTEGER,
                api_calls INTEGER,
                errors_count INTEGER,
                status TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # í†µê³„ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date DATE UNIQUE,
                total_news INTEGER,
                unique_news INTEGER,
                duplicates_removed INTEGER,
                cache_hit_rate REAL,
                avg_processing_time REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        
        logger.info("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {type(e).__name__} - {str(e)}")


def save_news_to_db(news_data: List[Dict]):
    """ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    if not config.DATABASE_CONFIG['enabled']:
        return
    
    try:
        conn = sqlite3.connect(config.DATABASE_CONFIG['path'])
        cursor = conn.cursor()
        
        saved_count = 0
        for news in news_data:
            try:
                cursor.execute('''
                    INSERT OR REPLACE INTO news 
                    (original_title, translated_title, short_summary, long_summary, 
                     category, url, source, publish_date, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                ''', (
                    news['original_title'],
                    news['translated_title'],
                    news['short_summary'],
                    news['long_summary'],
                    news['category'],
                    news['url'],
                    news['source'],
                    news['date']
                ))
                saved_count += 1
            except sqlite3.IntegrityError:
                # ì¤‘ë³µ URLì€ ë¬´ì‹œ
                continue
        
        conn.commit()
        conn.close()
        
        logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— {saved_count}ê°œ ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}")


def save_execution_log(start_time: float, end_time: float, news_count: int, 
                       cache_hits: int, api_calls: int, errors_count: int, status: str):
    """ì‹¤í–‰ ë¡œê·¸ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    if not config.DATABASE_CONFIG['enabled']:
        return
    
    try:
        conn = sqlite3.connect(config.DATABASE_CONFIG['path'])
        cursor = conn.cursor()
        
        duration = end_time - start_time
        
        cursor.execute('''
            INSERT INTO execution_logs 
            (start_time, end_time, duration_seconds, news_count, cache_hits, 
             api_calls, errors_count, status)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            datetime.fromtimestamp(start_time).isoformat(),
            datetime.fromtimestamp(end_time).isoformat(),
            duration,
            news_count,
            cache_hits,
            api_calls,
            errors_count,
            status
        ))
        
        conn.commit()
        conn.close()
        
        logger.info(f"ğŸ“Š ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}")


def get_statistics():
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í†µê³„ ì¡°íšŒ"""
    if not config.DATABASE_CONFIG['enabled']:
        return None
    
    try:
        conn = sqlite3.connect(config.DATABASE_CONFIG['path'])
        cursor = conn.cursor()
        
        # ì´ ë‰´ìŠ¤ ìˆ˜
        cursor.execute('SELECT COUNT(*) FROM news')
        total_news = cursor.fetchone()[0]
        
        # ì˜¤ëŠ˜ ìˆ˜ì§‘í•œ ë‰´ìŠ¤ ìˆ˜
        cursor.execute('''
            SELECT COUNT(*) FROM news 
            WHERE DATE(created_at) = DATE('now')
        ''')
        today_news = cursor.fetchone()[0]
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        cursor.execute('''
            SELECT category, COUNT(*) as count 
            FROM news 
            GROUP BY category 
            ORDER BY count DESC
        ''')
        category_stats = cursor.fetchall()
        
        conn.close()
        
        return {
            'total_news': total_news,
            'today_news': today_news,
            'category_stats': category_stats
        }
    except Exception as e:
        logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}")
        return None


# =========================================================
# ì•Œë¦¼ ì‹œìŠ¤í…œ
# =========================================================
def send_email_notification(subject: str, message: str):
    """ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡"""
    if not config.NOTIFICATION_CONFIG['email_enabled'] or not EMAIL_USER or not EMAIL_PASS:
        return
    
    try:
        msg = MIMEMultipart()
        msg['From'] = EMAIL_USER
        msg['To'] = config.SITE_INFO['contact_email']
        msg['Subject'] = f"[LUMEN] {subject}"
        
        body = MIMEText(message, 'plain', 'utf-8')
        msg.attach(body)
        
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PASS)
            server.send_message(msg)
        
        logger.info(f"ğŸ“§ ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: {subject}")
    except Exception as e:
        logger.error(f"âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}")


def send_slack_notification(message: str):
    """Slack ì•Œë¦¼ ì „ì†¡"""
    if not config.NOTIFICATION_CONFIG['slack_enabled'] or not SLACK_WEBHOOK_URL:
        return
    
    try:
        payload = {'text': f"[LUMEN] {message}"}
        response = requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=10)
        
        if response.status_code == 200:
            logger.info(f"ğŸ’¬ Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
        else:
            logger.warning(f"âš ï¸ Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        logger.error(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}")


def notify_error(error_message: str):
    """ì—ëŸ¬ ë°œìƒ ì‹œ ì•Œë¦¼"""
    if not config.NOTIFICATION_CONFIG['notify_on_error']:
        return
    
    send_email_notification("ì—ëŸ¬ ë°œìƒ", error_message)
    send_slack_notification(f"ğŸš¨ ì—ëŸ¬ ë°œìƒ: {error_message}")


def notify_success(summary: str):
    """ì„±ê³µ ì‹œ ì•Œë¦¼"""
    if not config.NOTIFICATION_CONFIG['notify_on_success']:
        return
    
    send_email_notification("ì‹¤í–‰ ì™„ë£Œ", summary)
    send_slack_notification(f"âœ… ì‹¤í–‰ ì™„ë£Œ: {summary}")


# =========================================================
# ìºì‹± ì‹œìŠ¤í…œ
# =========================================================
def init_cache():
    """ìºì‹œ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”"""
    if not config.CACHE_CONFIG['enabled']:
        return
    
    cache_dir = config.CACHE_CONFIG['directory']
    os.makedirs(cache_dir, exist_ok=True)
    logger.info(f"ğŸ“¦ ìºì‹œ ë””ë ‰í† ë¦¬ ì¤€ë¹„: {cache_dir}")


def get_cache_key(title: str) -> str:
    """ì œëª©ì„ MD5 í•´ì‹œë¡œ ë³€í™˜í•˜ì—¬ ìºì‹œ í‚¤ ìƒì„±"""
    return hashlib.md5(title.encode('utf-8')).hexdigest()


def get_cached_summary(title: str) -> Optional[Tuple[str, str, str, str]]:
    """ìºì‹œì—ì„œ ìš”ì•½ ë°ì´í„° ë¡œë“œ"""
    if not config.CACHE_CONFIG['enabled']:
        return None
    
    cache_key = get_cache_key(title)
    cache_dir = config.CACHE_CONFIG['directory']
    cache_file = os.path.join(cache_dir, f"{cache_key}.json")
    
    if not os.path.exists(cache_file):
        return None
    
    try:
        file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
        expiry_days = config.CACHE_CONFIG['expiry_days']
        
        if datetime.now() - file_time > timedelta(days=expiry_days):
            logger.debug(f"â° ìºì‹œ ë§Œë£Œ: {title[:30]}...")
            os.remove(cache_file)
            return None
        
        with open(cache_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            logger.info(f"ğŸ’¾ ìºì‹œ ì ì¤‘: {title[:30]}...")
            return (
                data['translated_title'],
                data['short_summary'],
                data['long_summary'],
                data['category']
            )
    except Exception as e:
        logger.warning(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}")
        return None


def save_to_cache(title: str, translated_title: str, short_summary: str, 
                  long_summary: str, category: str):
    """ìš”ì•½ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
    if not config.CACHE_CONFIG['enabled']:
        return
    
    try:
        cache_key = get_cache_key(title)
        cache_dir = config.CACHE_CONFIG['directory']
        cache_file = os.path.join(cache_dir, f"{cache_key}.json")
        
        data = {
            'original_title': title,
            'translated_title': translated_title,
            'short_summary': short_summary,
            'long_summary': long_summary,
            'category': category,
            'cached_at': datetime.now().isoformat()
        }
        
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.debug(f"ğŸ’¾ ìºì‹œ ì €ì¥: {title[:30]}...")
    except Exception as e:
        logger.warning(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {type(e).__name__}")


def clean_old_cache():
    """ì˜¤ë˜ëœ ìºì‹œ íŒŒì¼ ì •ë¦¬"""
    if not config.CACHE_CONFIG['enabled']:
        return
    
    cache_dir = config.CACHE_CONFIG['directory']
    if not os.path.exists(cache_dir):
        return
    
    expiry_days = config.CACHE_CONFIG['expiry_days']
    cleaned = 0
    
    for filename in os.listdir(cache_dir):
        filepath = os.path.join(cache_dir, filename)
        try:
            file_time = datetime.fromtimestamp(os.path.getmtime(filepath))
            if datetime.now() - file_time > timedelta(days=expiry_days):
                os.remove(filepath)
                cleaned += 1
        except Exception:
            continue
    
    if cleaned > 0:
        logger.info(f"ğŸ§¹ ì˜¤ë˜ëœ ìºì‹œ {cleaned}ê°œ ì •ë¦¬ ì™„ë£Œ")


# =========================================================
# ì¤‘ë³µ í•„í„°ë§
# =========================================================
def calculate_similarity(text1: str, text2: str) -> float:
    """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
    return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()


def is_duplicate(title: str, seen_titles: List[str]) -> bool:
    """ì œëª©ì´ ì¤‘ë³µì¸ì§€ í™•ì¸"""
    if not config.DEDUPLICATION_CONFIG['enabled']:
        return False
    
    threshold = config.DEDUPLICATION_CONFIG['similarity_threshold']
    
    for seen_title in seen_titles:
        if calculate_similarity(title, seen_title) >= threshold:
            return True
    return False


def remove_duplicates(news_list: List[Dict]) -> List[Dict]:
    """ì¤‘ë³µ ë‰´ìŠ¤ ì œê±°"""
    if not config.DEDUPLICATION_CONFIG['enabled']:
        return news_list
    
    unique_news = []
    seen_titles = []
    duplicates_count = 0
    
    for news in news_list:
        title = news['original_title']
        
        if is_duplicate(title, seen_titles):
            duplicates_count += 1
            logger.debug(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {title[:40]}...")
            continue
        
        unique_news.append(news)
        seen_titles.append(title)
    
    if duplicates_count > 0:
        logger.info(f"ğŸ”„ ì¤‘ë³µ ë‰´ìŠ¤ {duplicates_count}ê°œ ì œê±° ì™„ë£Œ")
    
    return unique_news


# =========================================================
# ë¹„ë™ê¸° AI ì²˜ë¦¬ (config ê¸°ë°˜)
# =========================================================
async def get_ai_summary_async(session: aiohttp.ClientSession, title: str) -> Tuple[str, str, str, str]:
    """ë¹„ë™ê¸°ë¡œ AI ë²ˆì—­ ë° ìš”ì•½ ìˆ˜í–‰"""
    # ìºì‹œ í™•ì¸
    cached = get_cached_summary(title)
    if cached:
        return cached
    
    logger.info(f"ğŸ¤– AI ì²˜ë¦¬ ì‹œì‘: {title[:50]}...")
    
    url = f"https://generativelanguage.googleapis.com/v1/models/{config.AI_CONFIG['model']}:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    
    categories_str = '\n- '.join(config.CATEGORIES)
    
    payload = {
        "contents": [{
            "parts": [{
                "text": f"""ë‹¹ì‹ ì€ 10ë…„ ì°¨ ë² í…Œë‘ ì†Œí™”ê¸°ë‚´ê³¼ ê°„í˜¸ì‚¬ì…ë‹ˆë‹¤.
ì•„ë˜ ì˜ì–´ ë‰´ìŠ¤ ì œëª©ì„ ë³´ê³  ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

1. ì œëª©: í•œêµ­ì–´ë¡œ ì˜ì—­ (ê°„ê²°í•˜ê²Œ, í•µì‹¬ë§Œ)
2. ì§§ì€ ìš”ì•½: 1-2ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë‚´ìš© ì„¤ëª…
3. ê¸´ ìš”ì•½: 3-4ë¬¸ì¥ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì„¤ëª…
4. ì¹´í…Œê³ ë¦¬: ì•„ë˜ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ

[ì¹´í…Œê³ ë¦¬ ì˜µì…˜]
- {categories_str}

ì˜ì–´ ë‰´ìŠ¤ ì œëª©: {title}

ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”.

ì œëª©: [í•œêµ­ì–´ ì œëª©]
ì¹´í…Œê³ ë¦¬: [ìœ„ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜]
ì§§ì€ìš”ì•½: [1-2ë¬¸ì¥]
ê¸´ìš”ì•½: [3-4ë¬¸ì¥]"""
            }]
        }],
        "generationConfig": {
            "temperature": config.AI_CONFIG['temperature'],
            "maxOutputTokens": config.AI_CONFIG['max_tokens']
        }
    }
    
    max_retries = config.AI_CONFIG['max_retries']
    timeout_val = config.AI_CONFIG['timeout']
    
    for attempt in range(max_retries):
        try:
            async with session.post(url, headers=headers, json=payload, timeout=timeout_val) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    if 'candidates' in result and len(result['candidates']) > 0:
                        candidate = result['candidates'][0]
                        
                        if 'content' in candidate and 'parts' in candidate['content']:
                            text = candidate['content']['parts'][0].get('text', '')
                            
                            if text:
                                parsed = parse_ai_response(text, title)
                                if parsed:
                                    logger.info(f"âœ… AI ì²˜ë¦¬ ì™„ë£Œ: [{parsed[3]}]")
                                    save_to_cache(title, *parsed)
                                    return parsed
                    
                    logger.warning(f"âš ï¸ AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries})")
                    
                elif response.status == 429:
                    wait_time = 2 ** attempt
                    logger.warning(f"âš ï¸ API ì†ë„ ì œí•œ (429) - {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                    
                else:
                    logger.error(f"âŒ API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status})")
                    
        except asyncio.TimeoutError:
            logger.warning(f"âš ï¸ API íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{max_retries})")
            await asyncio.sleep(1)
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {type(e).__name__} - {str(e)}")
            break
    
    logger.warning(f"âš ï¸ AI ì²˜ë¦¬ ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©: {title[:30]}...")
    return get_fallback_summary(title)


def parse_ai_response(text: str, original_title: str) -> Optional[Tuple[str, str, str, str]]:
    """AI ì‘ë‹µ í…ìŠ¤íŠ¸ íŒŒì‹±"""
    translated_title = original_title[:50]
    category = config.CATEGORIES[0]  # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬
    short_summary = ""
    long_summary = ""
    
    # ì œëª© ì¶”ì¶œ
    title_patterns = [
        r'\*\*ì œëª©\*\*:\s*(.+)',
        r'ì œëª©:\s*(.+)',
    ]
    for pattern in title_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            translated_title = re.sub(r'[\*\`]', '', match.group(1).strip()).split('\n')[0]
            break
    
    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    category_patterns = [
        r'\*\*ì¹´í…Œê³ ë¦¬\*\*:\s*(.+)',
        r'ì¹´í…Œê³ ë¦¬:\s*(.+)',
    ]
    for pattern in category_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            category = re.sub(r'[\*\`]', '', match.group(1).strip()).split('\n')[0]
            break
    
    # ì§§ì€ ìš”ì•½ ì¶”ì¶œ
    short_patterns = [
        r'\*\*ì§§ì€ìš”ì•½\*\*:\s*(.+)',
        r'ì§§ì€ìš”ì•½:\s*(.+)',
    ]
    for pattern in short_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            short_summary = re.sub(r'[\*\`]', '', match.group(1).strip())
            break
    
    # ê¸´ ìš”ì•½ ì¶”ì¶œ
    long_patterns = [
        r'\*\*ê¸´ìš”ì•½\*\*:\s*(.+)',
        r'ê¸´ìš”ì•½:\s*(.+)',
    ]
    for pattern in long_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        if match:
            remaining = text[match.start():]
            long_summary = ''
            for line in remaining.split('\n'):
                if line.strip() and not any(x in line for x in ['ì œëª©:', 'ì¹´í…Œê³ ë¦¬:', 'ì§§ì€ìš”ì•½:']):
                    clean_line = re.sub(r'^\*\*ê¸´ìš”ì•½\*\*:\s*|^ê¸´ìš”ì•½:\s*', '', line)
                    clean_line = re.sub(r'[\*\`]', '', clean_line)
                    if clean_line.strip():
                        long_summary += clean_line.strip() + ' '
            long_summary = long_summary.strip()
            if long_summary:
                break
    
    # ê²€ì¦
    if not translated_title or len(translated_title) < 5:
        translated_title = original_title[:50]
    
    if not short_summary or len(short_summary) < 10:
        short_summary = f"{translated_title} ê´€ë ¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤."
    
    if not long_summary or len(long_summary) < 20:
        long_summary = f"{translated_title} ê´€ë ¨ ì†Œì‹ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ ì°¸ì¡°í•˜ì„¸ìš”."
    
    return (translated_title, short_summary, long_summary, category)


def get_fallback_summary(title: str) -> Tuple[str, str, str, str]:
    """AI ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜"""
    translated_title = title[:50] + ("..." if len(title) > 50 else "")
    short_summary = f"{translated_title} ê´€ë ¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤."
    long_summary = f"{translated_title} ê´€ë ¨ ì†Œì‹ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ ì°¸ì¡°í•˜ì„¸ìš”."
    category = config.CATEGORIES[0]
    
    return (translated_title, short_summary, long_summary, category)


# =========================================================
# RSS í”¼ë“œ ìˆ˜ì§‘ (config ê¸°ë°˜)
# =========================================================
async def process_entries_async(session: aiohttp.ClientSession, entries: list, 
                                source_name: str, priority: int) -> List[Dict]:
    """RSS ì—”íŠ¸ë¦¬ë“¤ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬"""
    kst = timezone(timedelta(hours=9))
    tasks = []
    entries_data = []
    
    # configì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    feed_config = None
    for name, cfg in config.RSS_FEEDS.items():
        if name == source_name:
            feed_config = cfg
            break
    
    max_news = feed_config['max_news'] if feed_config else 5
    
    for entry in entries[:max_news]:
        try:
            pub_date = getattr(entry, 'published_parsed', None) or getattr(entry, 'updated_parsed', None)
            if pub_date:
                date_obj = datetime(*pub_date[:6], tzinfo=timezone.utc)
                date_kst = date_obj.astimezone(kst)
                formatted_date = date_kst.strftime("%Y-%m-%d")
            else:
                formatted_date = datetime.now(kst).strftime("%Y-%m-%d")
            
            original_title = entry.title
            url = entry.link
            
            if not original_title or not url:
                continue
            
            entries_data.append({
                'original_title': original_title,
                'url': url,
                'date': formatted_date,
                'source': source_name,
                'priority': f"TOP {priority}"
            })
            
            tasks.append(get_ai_summary_async(session, original_title))
            
        except Exception as e:
            logger.error(f"âŒ ì—”íŠ¸ë¦¬ íŒŒì‹± ì‹¤íŒ¨: {type(e).__name__}")
            continue
    
    if tasks:
        logger.info(f"âš¡ {len(tasks)}ê°œ ë‰´ìŠ¤ë¥¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...")
        ai_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        news_list = []
        for entry_data, ai_result in zip(entries_data, ai_results):
            if isinstance(ai_result, Exception):
                logger.error(f"âŒ AI ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {type(ai_result).__name__}")
                continue
            
            translated_title, short_summary, long_summary, category = ai_result
            
            news_list.append({
                **entry_data,
                'translated_title': translated_title,
                'short_summary': short_summary,
                'long_summary': long_summary,
                'category': category
            })
        
        return news_list
    
    return []


async def fetch_single_feed_async(session: aiohttp.ClientSession, source_name: str, 
                                  feed_config: Dict, priority: int) -> List[Dict]:
    """ë‹¨ì¼ RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë¹„ë™ê¸°)"""
    if not feed_config['enabled']:
        logger.info(f"â­ï¸ {source_name}: ë¹„í™œì„±í™”ë¨")
        return []
    
    try:
        logger.info(f"ğŸ“¡ {source_name} ìˆ˜ì§‘ ì¤‘...")
        
        loop = asyncio.get_event_loop()
        feed = await loop.run_in_executor(None, feedparser.parse, feed_config['url'])
        
        if not feed.entries:
            logger.warning(f"âš ï¸ {source_name}: ë‰´ìŠ¤ ì—†ìŒ")
            return []
        
        news_list = await process_entries_async(session, feed.entries, source_name, priority)
        
        logger.info(f"âœ… {source_name}: {len(news_list)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return news_list
        
    except Exception as e:
        logger.error(f"âŒ {source_name} RSS í”¼ë“œ ì˜¤ë¥˜: {type(e).__name__} - {str(e)}")
        return []


async def fetch_rss_feeds_async() -> List[Dict]:
    """ëª¨ë“  RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)"""
    logger.info("=" * 60)
    logger.info("ğŸ“° RSS í”¼ë“œ ìˆ˜ì§‘ ì‹œì‘ (ë¹„ë™ê¸° ëª¨ë“œ)")
    logger.info("=" * 60)
    
    timeout = aiohttp.ClientTimeout(total=60)
    async with aiohttp.ClientSession(timeout=timeout) as session:
        tasks = [
            fetch_single_feed_async(session, source_name, feed_config, idx)
            for idx, (source_name, feed_config) in enumerate(config.RSS_FEEDS.items(), 1)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_news = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"âŒ í”¼ë“œ ìˆ˜ì§‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {type(result).__name__}")
                continue
            all_news.extend(result)
    
    logger.info("=" * 60)
    logger.info(f"âœ… ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
    logger.info("=" * 60)
    
    return all_news


# =========================================================
# HTML ìƒì„± (config ê¸°ë°˜)
# =========================================================
def generate_html(news_list: List[Dict]) -> str:
    """ë‰´ìŠ¤ ëª©ë¡ìœ¼ë¡œ HTML ìƒì„±"""
    kst = timezone(timedelta(hours=9))
    current_date = datetime.now(kst).strftime("%Yë…„ %mì›” %dì¼")
    
    # ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´ ìƒì„±
    nav_items = ""
    for item in config.NAVIGATION_MENU:
        nav_items += f'<li><a href="{item["link"]}">{item["icon"]} {item["text"]}</a></li>\n            '
    
    html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{config.SITE_INFO['title']}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: 'Segoe UI', 'Apple SD Gothic Neo', sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: #333; line-height: 1.6; }}
        
        header {{ background: linear-gradient(135deg, #003366 0%, #004d99 100%); color: white; text-align: center; padding: 2rem 1rem; box-shadow: 0 4px 12px rgba(0,0,0,0.2); }}
        header h1 {{ font-size: 2.5rem; margin-bottom: 0.5rem; text-shadow: 2px 2px 4px rgba(0,0,0,0.3); }}
        header .update {{ font-size: 0.95rem; opacity: 0.9; }}
        
        nav {{ background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.1); position: sticky; top: 0; z-index: 100; }}
        nav ul {{ list-style: none; display: flex; justify-content: center; flex-wrap: wrap; padding: 1rem; gap: 1.5rem; }}
        nav ul li a {{ text-decoration: none; color: #003366; font-weight: 500; padding: 0.5rem 1rem; border-radius: 6px; transition: all 0.3s; }}
        nav ul li a:hover {{ background: #003366; color: white; }}
        
        .container {{ max-width: 1200px; margin: 2rem auto; padding: 0 1rem; }}
        
        .disclaimer-banner {{ background: #fff3cd; border: 2px solid #ffc107; border-radius: 8px; padding: 1rem; margin-bottom: 2rem; }}
        .disclaimer-banner p {{ color: #856404; font-size: 0.95rem; }}
        .disclaimer-banner a {{ color: #003366; font-weight: 600; text-decoration: underline; }}
        
        .stats-inline {{ display: flex; justify-content: center; gap: 2rem; margin-bottom: 2rem; flex-wrap: wrap; }}
        .stat-item {{ background: white; padding: 1rem 1.5rem; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); text-align: center; }}
        .stat-item .number {{ display: block; font-size: 2rem; font-weight: 700; color: #003366; }}
        .stat-item .label {{ display: block; font-size: 0.9rem; color: #666; margin-top: 0.25rem; }}
        
        .grid {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(320px, 1fr)); gap: 1.5rem; }}
        
        .card {{ background: white; border-radius: 12px; padding: 1.5rem; box-shadow: 0 4px 12px rgba(0,0,0,0.1); transition: all 0.3s; cursor: pointer; position: relative; }}
        .card:hover {{ transform: translateY(-5px); box-shadow: 0 8px 20px rgba(0,0,0,0.2); }}
        .tag {{ display: inline-block; padding: 0.4rem 0.8rem; border-radius: 20px; font-size: 0.85rem; font-weight: 600; margin-bottom: 0.75rem; }}
        .tag-tech {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }}
        .tag-regulation {{ background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; }}
        .tag-research {{ background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color: white; }}
        .tag-safety {{ background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%); color: white; }}
        .tag-education {{ background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); color: white; }}
        .source-badge {{ position: absolute; top: 1rem; right: 1rem; background: #FFD700; color: #003366; padding: 0.3rem 0.6rem; border-radius: 6px; font-size: 0.75rem; font-weight: 700; }}
        .title {{ font-size: 1.2rem; font-weight: 700; color: #003366; margin-bottom: 0.75rem; line-height: 1.4; }}
        .summary {{ color: #666; font-size: 0.95rem; margin-bottom: 1rem; line-height: 1.6; }}
        .meta {{ display: flex; justify-content: space-between; font-size: 0.85rem; color: #999; }}
        
        .modal {{ display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,0.7); }}
        .modal-content {{ background-color: white; margin: 5% auto; padding: 2rem; border-radius: 12px; width: 90%; max-width: 700px; max-height: 80vh; overflow-y: auto; position: relative; box-shadow: 0 10px 40px rgba(0,0,0,0.3); }}
        .close {{ color: #aaa; float: right; font-size: 2rem; font-weight: bold; cursor: pointer; line-height: 1; }}
        .close:hover {{ color: #000; }}
        .modal-title {{ font-size: 1.6rem; font-weight: 700; color: #003366; margin-bottom: 1rem; padding-right: 2rem; }}
        .modal-original-title {{ font-size: 1rem; color: #666; margin-bottom: 1.5rem; padding: 1rem; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #003366; }}
        .modal-summary {{ font-size: 1.05rem; color: #333; line-height: 1.8; margin-bottom: 1.5rem; }}
        .modal-meta {{ display: flex; justify-content: space-between; font-size: 0.9rem; color: #888; margin-bottom: 1.5rem; flex-wrap: wrap; gap: 0.5rem; }}
        .btn {{ display: inline-block; background: linear-gradient(135deg, #003366 0%, #004d99 100%); color: white; padding: 0.8rem 2rem; border-radius: 6px; text-decoration: none; transition: all 0.3s; font-weight: 500; box-shadow: 0 2px 6px rgba(0,51,102,0.3); }}
        .btn:hover {{ background: linear-gradient(135deg, #004d99 0%, #003366 100%); transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0,51,102,0.4); }}
        
        .about {{ background: white; padding: 1.5rem; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-top: 3rem; border-left: 4px solid #FFD700; }}
        .about h3 {{ color: #003366; margin-bottom: 1rem; }}
        .about p {{ color: #666; font-size: 0.95rem; }}
        
        footer {{ background: #003366; color: white; text-align: center; padding: 2rem; margin-top: 2rem; }}
        footer a {{ color: #FFD700; text-decoration: none; }}
        footer a:hover {{ text-decoration: underline; }}
        
        @media (max-width: 768px) {{
            header h1 {{ font-size: 1.8rem; }}
            .grid {{ grid-template-columns: 1fr; }}
            .stats-inline {{ flex-direction: column; align-items: flex-start; }}
            nav ul {{ flex-direction: column; align-items: center; gap: 1rem; }}
            .modal-content {{ width: 95%; margin: 10% auto; padding: 1.5rem; }}
        }}
    </style>
</head>
<body>
    <header>
        <h1>{config.SITE_INFO['name']}</h1>
        <p class="update">ğŸ“… {current_date}</p>
    </header>
    
    <nav>
        <ul>
            {nav_items}
        </ul>
    </nav>
    
    <div class="container">
        <div class="disclaimer-banner">
            <p><strong>âš ï¸ ì˜ë£Œ ì •ë³´ ì•ˆë‚´:</strong> ë³¸ ì‚¬ì´íŠ¸ì˜ ì •ë³´ëŠ” êµìœ¡ ëª©ì ì´ë©° ì˜í•™ì  ì¡°ì–¸ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
            ìì„¸í•œ ë‚´ìš©ì€ <a href="disclaimer.html">ë©´ì±…ì¡°í•­</a>ì„ ì°¸ê³ í•˜ì„¸ìš”.</p>
        </div>
        <div class="stats-inline">
            <div class="stat-item">
                <span class="number">{len(news_list)}</span>
                <span class="label">ê°œ ë‰´ìŠ¤</span>
            </div>
"""
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    category_counts = {}
    for news in news_list:
        cat = news['category']
        category_counts[cat] = category_counts.get(cat, 0) + 1
    
    for category, count in category_counts.items():
        html += f"""
            <div class="stat-item">
                <span class="number">{count}</span>
                <span class="label">{category}</span>
            </div>
"""
    
    html += """
        </div>
        
        <div class="grid">
"""
    
    # ë‰´ìŠ¤ ì¹´ë“œ ìƒì„±
    for idx, news in enumerate(news_list):
        tag_class = config.CATEGORY_TAG_CLASS.get(news['category'], "tag-research")
        
        html += f"""
            <div class="card" onclick="openModal({idx})">
                <span class="tag {tag_class}">{news['category']}</span>
                <span class="source-badge">{news['priority']}</span>
                <h3 class="title">{news['translated_title']}</h3>
                <p class="summary">{news['short_summary']}</p>
                <div class="meta">
                    <span>ğŸ“° {news['source']}</span>
                    <span>{news['date']}</span>
                </div>
            </div>
"""
    
    html += """
        </div>
        
        <div class="about">
            <h3>ğŸ©º LUMENì´ë€?</h3>
            <p>""" + config.SITE_INFO['description'] + """</p>
        </div>
    </div>
    
    <!-- ëª¨ë‹¬ íŒì—… -->
"""
    
    # ê° ë‰´ìŠ¤ë³„ ëª¨ë‹¬ ìƒì„±
    for idx, news in enumerate(news_list):
        tag_class = config.CATEGORY_TAG_CLASS.get(news['category'], "tag-research")
        html += f"""
    <div id="modal{idx}" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal({idx})">&times;</span>
            <span class="tag {tag_class}">{news['category']}</span>
            <h2 class="modal-title">{news['translated_title']}</h2>
            <div class="modal-original-title">
                <strong>ì›ë¬¸ ì œëª©:</strong> {news['original_title']}
            </div>
            <p class="modal-summary">{news['long_summary']}</p>
            <div class="modal-meta">
                <span>ğŸ“° {news['source']}</span>
                <span>{news['date']}</span>
            </div>
            <a href="{news['url']}" target="_blank" rel="noopener noreferrer" class="btn">ì›ë¬¸ ë³´ê¸° â†’</a>
        </div>
    </div>
"""
    
    # í‘¸í„° ë©”ë‰´ ìƒì„±
    footer_links = " | ".join([f'<a href="{item["link"]}">{item["text"]}</a>' for item in config.NAVIGATION_MENU])
    
    html += f"""
    
    <footer>
        <p>Â© 2024 <a href="index.html">{config.SITE_INFO['name']}</a> | {footer_links}</p>
        <p style="margin-top: 0.5rem; font-size: 0.85rem; opacity: 0.8;">
            AI íë ˆì´ì…˜ | ë§¤ì¼ ì˜¤ì „ 8ì‹œ ì—…ë°ì´íŠ¸ | ë¬¸ì˜: {config.SITE_INFO['contact_email']}
        </p>
    </footer>
    
    <script>
        function openModal(index) {{
            document.getElementById('modal' + index).style.display = 'block';
            document.body.style.overflow = 'hidden';
        }}
        
        function closeModal(index) {{
            document.getElementById('modal' + index).style.display = 'none';
            document.body.style.overflow = 'auto';
        }}
        
        window.onclick = function(event) {{
            if (event.target.classList.contains('modal')) {{
                event.target.style.display = 'none';
                document.body.style.overflow = 'auto';
            }}
        }}
    </script>
</body>
</html>
    """
    return html


# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================
async def main_async():
    """ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜"""
    start_time = time.time()
    cache_hits = 0
    api_calls = 0
    errors_count = 0
    status = "success"
    
    try:
        logger.info("\n" + "=" * 60)
        logger.info("ğŸš€ LUMEN ì‹œìŠ¤í…œ ì‹œì‘ (ì¤‘ê¸° ê°œì„  ì™„ë£Œ ë²„ì „)")
        logger.info("=" * 60)
        logger.info("âœ¨ ì ìš©ëœ ê°œì„ ì‚¬í•­:")
        logger.info("  âš¡ ë¹„ë™ê¸° ì²˜ë¦¬ (5-10ë°° ì†ë„ í–¥ìƒ)")
        logger.info("  ğŸ’¾ ìºì‹± ì‹œìŠ¤í…œ (API ë¹„ìš© 60-70% ì ˆê°)")
        logger.info("  ğŸ”„ ì¤‘ë³µ ë‰´ìŠ¤ í•„í„°ë§ (ì½˜í…ì¸  í’ˆì§ˆ í–¥ìƒ)")
        logger.info("  ğŸ“ ì„¤ì • íŒŒì¼ ë¶„ë¦¬ (ìœ ì§€ë³´ìˆ˜ í¸ë¦¬)")
        logger.info("  ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ë„ì… (íˆìŠ¤í† ë¦¬ ê´€ë¦¬)")
        logger.info("  ğŸ“§ ì—ëŸ¬ ì•Œë¦¼ ì‹œìŠ¤í…œ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§)")
        logger.info("=" * 60 + "\n")
        
        # ì´ˆê¸°í™”
        init_cache()
        clean_old_cache()
        init_database()
        
        # RSS í”¼ë“œ ìˆ˜ì§‘
        news_data = await fetch_rss_feeds_async()
        
        if not news_data:
            logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            status = "no_news"
            notify_error("ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì¤‘ë³µ ì œê±°
            original_count = len(news_data)
            news_data = remove_duplicates(news_data)
            final_count = len(news_data)
            
            logger.info(f"ğŸ“Š ì¤‘ë³µ ì œê±° ê²°ê³¼: {original_count}ê°œ â†’ {final_count}ê°œ")
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            save_news_to_db(news_data)
        
        # HTML ìƒì„±
        logger.info("ğŸ”§ HTML íŒŒì¼ ìƒì„± ì¤‘...")
        final_html = generate_html(news_data)
        
        output_file = config.OUTPUT_CONFIG['html_file']
        with open(output_file, "w", encoding=config.OUTPUT_CONFIG['encoding']) as f:
            f.write(final_html)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ì‹¤í–‰ ë¡œê·¸ ì €ì¥
        save_execution_log(start_time, end_time, len(news_data), cache_hits, api_calls, errors_count, status)
        
        logger.info("=" * 60)
        logger.info(f"âœ… ì™„ë£Œ! {output_file} íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        logger.info("=" * 60)
        logger.info(f"\nâ±ï¸ ì„±ëŠ¥ í†µê³„:")
        logger.info(f"  â€¢ ì „ì²´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"  â€¢ ìµœì¢… ë‰´ìŠ¤ ìˆ˜: {len(news_data)}ê°œ")
        
        # ìºì‹œ í†µê³„
        if config.CACHE_CONFIG['enabled'] and os.path.exists(config.CACHE_CONFIG['directory']):
            cache_count = len(os.listdir(config.CACHE_CONFIG['directory']))
            logger.info(f"  â€¢ ìºì‹œëœ í•­ëª©: {cache_count}ê°œ")
        
        # DB í†µê³„
        if config.DATABASE_CONFIG['enabled']:
            stats = get_statistics()
            if stats:
                logger.info(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:")
                logger.info(f"  â€¢ ì´ ì €ì¥ëœ ë‰´ìŠ¤: {stats['total_news']}ê°œ")
                logger.info(f"  â€¢ ì˜¤ëŠ˜ ìˆ˜ì§‘í•œ ë‰´ìŠ¤: {stats['today_news']}ê°œ")
        
        # ì„±ê³µ ì•Œë¦¼
        summary = f"ì‹¤í–‰ ì™„ë£Œ: {len(news_data)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ({total_time:.2f}ì´ˆ)"
        notify_success(summary)
        
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        status = "interrupted"
        exit(0)
        
    except Exception as e:
        logger.error(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {str(e)}")
        import traceback
        error_detail = traceback.format_exc()
        logger.error(error_detail)
        
        status = "error"
        errors_count = 1
        notify_error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {type(e).__name__} - {str(e)}")
        exit(1)


if __name__ == "__main__":
    asyncio.run(main_async())
